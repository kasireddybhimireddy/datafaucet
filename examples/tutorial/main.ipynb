{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datafaucet\n",
    "\n",
    "Datafaucet is a productivity framework for ETL, ML application. Simplifying some of the common activities which are typical in Data pipeline such as project scaffolding, data ingesting, start schema generation, forecasting etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles\n",
    "\n",
    "- Both notebooks and code files are first citizens\n",
    "\n",
    "Following python package conventions, the root of the project is tagged by a `__main__.py` and directory of source code (either python or notebooks) contains the `__init__.py` code. By doing so, python and notebook files can reference each other.\n",
    "\n",
    "Python notebooks and Python code can be mixed and matched, and are interoperable with each other. By using datafaucet, you can include notebooks as modules to python code, and you can include python modules in a notebook. \n",
    "\n",
    "- Decouple Code and Data Resources\n",
    "\n",
    "Data can be located anywhere, on remote HDFS clusters, or Object Store Services exposed via S3 protocols etc. Also you can keep data on the local file system. No matter where data is located, we want to de-couple data resources from the code executed in the data pipeline.\n",
    "\n",
    "Separating data and code is done by declaring all data resources/providers as configuration in metadata files. Metadata files make possible to define aliases for data resources, data services and engine configurations, and keeping the ETL and ML code tidy with no hardcoded parameters.\n",
    "\n",
    "- Decouple Code from Configuration\n",
    "\n",
    "Code either stored as notebooks or as python files should be decoupled from both engine configurations and from data locations. All configuration is kept in metadata yaml files. Multiple setups for test, exploration, production can be defined as different metadata configuration profiles. Profiles can inherit configurations settings from other profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapters\n",
    "\n",
    "#### How to\n",
    "  - [Installing](install.ipynb)\n",
    "  - [Engine](engine.ipynb)\n",
    "  - [Metadata](metadata.ipynb)\n",
    "  - [Project](project.ipynb)\n",
    "  - [Resources](resources.ipynb)\n",
    "  - [Load and Save](loadsave.ipynb)\n",
    "  - [Logging](logging.ipynb)\n",
    "  - [Scaffolding](scaffolding.ipynb)\n",
    "  - [CLI](run.ipynb)\n",
    "  \n",
    "#### Data Ingest\n",
    "  - [Copy: overwrite/append](ingest.ipynb)\n",
    "  - [Log: slow changing dimensions](change.ipynb)\n",
    "  \n",
    "#### ETL\n",
    "  - [Merge Tables](merge.ipynb)\n",
    "  - [Fact Table](facts.ipynb)\n",
    "  - [Star Schema](star.ipynb)\n",
    "\n",
    "#### Aggregation\n",
    "  - [Aggregated data](aggregate.ipynb)\n",
    "  - [Publishing cubes](publish.ipynb)\n",
    "  \n",
    "#### Reporting\n",
    "  - Interactive\n",
    "  - BI tools\n",
    "  - Publish\n",
    "\n",
    "#### Pipelines:\n",
    "  - CI/CD\n",
    "  - DTAP\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
