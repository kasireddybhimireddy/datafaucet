{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datafaucet\n",
    "\n",
    "Datafaucet is a productivity framework for ETL, ML application. Simplifying some of the common activities which are typical in Data pipeline such as project scaffolding, data ingesting, start schema generation, forecasting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datafaucet as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created SparkEngine\n",
      "Init engine \"spark\"\n",
      "Connecting to spark master: local[*]\n",
      "Engine context spark:2.4.4 successfully started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datafaucet.project.Project at 0x7f6841f470b8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.project.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal(a,b):\n",
    "    cnt = a.exceptAll(b).count() + b.exceptAll(a).count()\n",
    "    return cnt==0\n",
    "\n",
    "def mask_rootdir(resource):\n",
    "    d = resource.copy()\n",
    "    if d['service']=='file':\n",
    "        d['url'] = '<project_rootdir>/' + dfc.utils.relpath(d['url'], dfc.rootdir())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local files\n",
    "\n",
    "The following show some load/save round trip on the local file system using various formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b     c\n",
       "0  yes  1  1.41\n",
       "1   no  0  3.14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "df = dfc.load('data/sample.csv')\n",
    "df.data.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hash: '0x738d9a97'\n",
       "url: <project_rootdir>/data/sample.csv\n",
       "service: file\n",
       "version:\n",
       "format: csv\n",
       "host: 127.0.0.1\n",
       "options: {}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dfc.Resource('data/sample.csv')\n",
    "mask_rootdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save in various format\n",
    "dfc.save(df, 'data/save/foo.csv')\n",
    "dfc.save(df, 'data/save/foo.json')\n",
    "dfc.save(df, 'data/save/foo.parquet')\n",
    "\n",
    "# with various compression\n",
    "dfc.save(df, 'data/save/foo.json.bz2')\n",
    "dfc.save(df, 'data/save/foo.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using format specific save\n",
    "\n",
    "dfc.save(df, 'data/save/bar.1', format='csv')\n",
    "dfc.save(df, 'data/save/bar.2', format='json')\n",
    "dfc.save(df, 'data/save/bar.3', format='parquet')\n",
    "\n",
    "# with various compression\n",
    "dfc.save(df, 'data/save/bar.4', format='csv', compression='bzip2')\n",
    "dfc.save(df, 'data/save/bar.5', format='json', compression='gzip')\n",
    "dfc.save(df, 'data/save/bar.6', format='parquet', compression='gzip')\n",
    "dfc.save(df, 'data/save/bar.7', format='parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round trip reading\n",
    "df_tst = dfc.load('data/save/foo.csv')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/foo.json')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/foo.parquet')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/foo.json.bz2')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/foo.csv.gz')\n",
    "assert(equal(df,df_tst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round trip reading (format specific load)\n",
    "df_tst = dfc.load('data/save/bar.1', format='csv')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/bar.2', format='json')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/bar.3', format='parquet')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "# df_tst = dfc.load('data/save/bar.4', format='csv', compression='bzip2')\n",
    "# assert(equal(df,df_tst))\n",
    "\n",
    "# df_tst = dfc.load('data/save/bar.5', format='json', compression='gzip')\n",
    "# assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/bar.6', format='parquet', compression='gzip')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/save/bar.7', format='parquet', compression='snappy')\n",
    "assert(equal(df,df_tst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from HDFS\n",
    "\n",
    "We can override the default resource provider, \n",
    "by explicitely passing a different provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.save(df, 'data/examples/bar.csv', 'hdfs')\n",
    "dfc.save(df, 'data/examples/bar.json', 'hdfs')\n",
    "dfc.save(df, 'data/examples/bar.parquet', 'hdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = dfc.load('data/examples/bar.csv', 'hdfs')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/examples/bar.json', 'hdfs')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/examples/bar.parquet', 'hdfs')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from Minio\n",
    "\n",
    "We can override the default resource provider, \n",
    "by explicitely passing a different provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.save(df, 'data/examples/bar.csv', 'minio')\n",
    "dfc.save(df, 'data/examples/bar.json', 'minio')\n",
    "dfc.save(df, 'data/examples/bar.parquet', 'minio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = dfc.load('data/examples/bar.csv', 'minio')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/examples/bar.json', 'minio')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dfc.load('data/examples/bar.parquet', 'minio')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from Web (HTTP/HTTPS)\n",
    "\n",
    "Files from web will be first downloaded locally on the driver, then passed to spark ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/natbusa/dfc-tutorial/master/data/examples/sample.csv\n",
      "Downloaded 27 bytes\n"
     ]
    }
   ],
   "source": [
    "df_tst = dfc.load('https://raw.githubusercontent.com/natbusa/datafaucet/master/examplesdata/examples/sample.csv')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from a Database (via jdbc connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MySQL: Sakila DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|last_name|amount|\n",
      "+---------+------+\n",
      "|    ABNEY|    21|\n",
      "|     ADAM|    28|\n",
      "|    ADAMS|    27|\n",
      "|ALEXANDER|    27|\n",
      "|   ALLARD|    32|\n",
      "|    ALLEN|    31|\n",
      "|  ALVAREZ|    27|\n",
      "| ANDERSON|    24|\n",
      "|   ANDREW|    25|\n",
      "|  ANDREWS|    23|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT c.last_name,\n",
    "        COUNT(p.amount) AS amount\n",
    "    FROM customer c\n",
    "    LEFT JOIN payment p\n",
    "        ON c.customer_id = p.customer_id\n",
    "    WHERE c.last_name like 'A%'\n",
    "    GROUP BY  c.last_name\n",
    "    ORDER BY  c.last_name ASC\n",
    "    LIMIT 10;\n",
    "\"\"\"\n",
    "dfc.load(query, 'sakila').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|customer_id|store_id|first_name|last_name|               email|address_id|active|        create_date|        last_update|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|          1|       1|      MARY|    SMITH|MARY.SMITH@sakila...|         5|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|PATRICIA.JOHNSON@...|         6|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          3|       1|     LINDA| WILLIAMS|LINDA.WILLIAMS@sa...|         7|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          4|       2|   BARBARA|    JONES|BARBARA.JONES@sak...|         8|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          5|       1| ELIZABETH|    BROWN|ELIZABETH.BROWN@s...|         9|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfc.load('customer', 'sakila',hint_index='customer_id', predicates=['last_update > 2019-10-10'], partitions=10).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+\n",
      "|customer_id|store_id|first_name|last_name|\n",
      "+-----------+--------+----------+---------+\n",
      "|          1|       1|      MARY|    SMITH|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|\n",
      "|          3|       1|     LINDA| WILLIAMS|\n",
      "|          4|       2|   BARBARA|    JONES|\n",
      "|          5|       1| ELIZABETH|    BROWN|\n",
      "|          6|       2|  JENNIFER|    DAVIS|\n",
      "|          7|       1|     MARIA|   MILLER|\n",
      "|          8|       2|     SUSAN|   WILSON|\n",
      "|          9|       2|  MARGARET|    MOORE|\n",
      "|         10|       1|   DOROTHY|   TAYLOR|\n",
      "+-----------+--------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dfc.load('customer', 'sakila')\n",
    "df.select('customer_id', 'store_id', 'first_name', 'last_name').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clickhouse: Taxes DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "|      total_emv|   total_tbea|      total_bav|           tax_class|tax_rate|\n",
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "|      1.31511E8|    3015446.0|     2.345737E7|2a - 4-6 unit res...|12.8550%|\n",
      "|    2.3639859E8|    7038237.0|    5.4750993E7| 2c - co-op or co...|12.8550%|\n",
      "|        7.778E7|    2107258.0|    1.6392523E7|2b - 7-10 unit re...|12.8550%|\n",
      "|2.5456025934E10|1.119343167E9|1.0476817274E10|4 - commercial pr...|10.6840%|\n",
      "|      1442000.0|      72190.0|       648900.0|3 - utility property|11.1250%|\n",
      "|            0.0|    1574279.0|      1574279.0|                    |        |\n",
      "|  7.279443191E9| 3.69685076E8|  2.875808079E9| 2 - residential,...|12.8550%|\n",
      "|      1.31918E8|     979489.0|      5112968.0| 1 - small home, ...|19.1570%|\n",
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        SUM(emv) as total_emv, \n",
    "        SUM(tbea) as total_tbea, \n",
    "        SUM(bav) as total_bav, \n",
    "        tax_class,\n",
    "        tax_rate \n",
    "    FROM tax_bills_nyc \n",
    "    GROUP BY tax_class, tax_rate\n",
    "\"\"\"\n",
    "dfc.load(query, 'taxes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+---------+------+------------+-----------+-----+\n",
      "|       bbl|          owner_name|             address|           tax_class|tax_rate|      emv|    tbea|      bav|   tba|property_tax|condonumber|condo|\n",
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+---------+------+------------+-----------+-----+\n",
      "|1000640023|       14 MAIDEN LLC|14 MAIDEN LLC\\n31...|2b - 7-10 unit re...|12.8550%| 1.0226E7|122161.0| 950300.0|122161|      122161|           |     |\n",
      "|1000930028|169 BEEKMAN ASSOC...|169 BECKMAN ASSOC...|2b - 7-10 unit re...|12.8550%|3652000.0| 44609.0| 347014.0| 44609|       44609|           |     |\n",
      "|1001070044|265 267 WATER ST....|265 267 WATER ST....|2b - 7-10 unit re...|12.8550%|6229000.0| 68563.0| 533360.0| 68563|       68563|           |     |\n",
      "|1000190018|44 TRINITY PLACE LLC|44 TRINITY PLACE ...|2b - 7-10 unit re...|12.8550%|3088000.0|137234.0|1067552.0|137234|      137234|           |     |\n",
      "|1001240021|        6 MURRAY LLC|6 MURRAY LLC\\n6 M...|2b - 7-10 unit re...|12.8550%|3176000.0|157361.0|1224124.0|157361|      157361|           |     |\n",
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+---------+------+------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfc.load('tax_bills_nyc', 'taxes').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSSql: School DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------+------------+\n",
      "|CourseID|      Title|Credits|DepartmentID|\n",
      "+--------+-----------+-------+------------+\n",
      "|    1045|   Calculus|      4|           7|\n",
      "|    1050|  Chemistry|      4|           1|\n",
      "|    1061|    Physics|      4|           1|\n",
      "|    2021|Composition|      3|           2|\n",
      "|    2030|     Poetry|      2|           2|\n",
      "+--------+-----------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfc.load('course', 'school').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oracle: HR DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|          HIRE_DATE| JOB_ID|  SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|2003-06-17 00:00:00|AD_PRES|24000.00|          null|      null|           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|2005-09-21 00:00:00|  AD_VP|17000.00|          null|       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|2001-01-13 00:00:00|  AD_VP|17000.00|          null|       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|2006-01-03 00:00:00|IT_PROG| 9000.00|          null|       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|2007-05-21 00:00:00|IT_PROG| 6000.00|          null|       103|           60|\n",
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfc.load('employees', 'human_resources').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postgres: Pagila DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|   sum|customer_id|\n",
      "+------+-----------+\n",
      "| 90.77|        184|\n",
      "|145.70|         87|\n",
      "|109.78|        477|\n",
      "|157.65|        273|\n",
      "|159.68|        550|\n",
      "+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query from resource\n",
    "md = dfc.Resource('select CAST(sum(amount) as DECIMAL(8,2)), customer_id from payment group by customer_id', 'pagila')\n",
    "dfc.load(md).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use JOIN to display the total amount rung up by each staff member\n",
    "# use tables 'staff' and 'payment'\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        CAST(SUM(p.amount) AS DECIMAL(16,2)) as total_sales, \n",
    "        s.last_name, \n",
    "        s.first_name\n",
    "    FROM payment p \n",
    "    INNER JOIN staff s ON p.staff_id = s.staff_id \n",
    "    GROUP BY s.last_name, s.first_name\n",
    "    \"\"\"\n",
    "df = dfc.load(query, 'pagila')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = dfc.Resource('total_sales', 'pagila')\n",
    "dfc.save(df, md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# round trip read back\n",
    "df = dfc.load('total_sales', 'pagila')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datafaucet 0.8.2\n"
     ]
    }
   ],
   "source": [
    "# check if the pyspark DataFrame class is monkey patched\n",
    "df.datafaucet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33489.47</td>\n",
       "      <td>Hillyer</td>\n",
       "      <td>Mike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  total_sales last_name first_name\n",
       "0    33489.47   Hillyer       Mike"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data.collect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   12345.67|   Dereck|       Eve|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a new dataframe from the original one, \n",
    "# by providing new data and retaining the original schema\n",
    "\n",
    "from decimal import Decimal as d\n",
    "df = df.rows.overwrite([(d(12345.67),'Dereck', 'Eve')])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "|   12345.67|   Dereck|       Eve|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# append new records and reload\n",
    "dfc.save(df, 'total_sales', 'pagila', mode='append')\n",
    "dfc.load('total_sales', 'pagila').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From one provider to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.load('payment', 'pagila').save('data/payment', 'hdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfc.load('payment', 'pagila')\n",
    "    .rows.filter_by_date('updated', from='12-2-2', to='78/543/5')\n",
    "    .cols.rename('up', 'update')\n",
    "    .withColumn('ds', 'hash')\n",
    "    .rows.pack([1,'yearmonth'])\n",
    "    .save('data/payment', 'hdfs', mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
